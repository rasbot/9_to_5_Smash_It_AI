Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
3000,1.4189386,23.112,-0.10606061,-5.428169799908515,-5.428169799908515,1.0
6000,1.4189385,25.651785714285715,-0.10344476,-6.256350340041439,-6.256350340041439,1.0
9000,1.4189385,22.107692307692307,-0.09511503,-5.840125627701099,-5.840125627701099,1.0
12000,1.4189385,23.483606557377048,-0.10365279,-5.8981359004974365,-5.8981359004974365,1.0
15000,1.4189385,25.0,-0.11131089,-5.876599804080766,-5.876599804080766,1.0
18000,1.4189385,23.826446280991735,-0.10274625,-5.724465013535554,-5.724465013535554,1.0
21000,1.4188571,24.48739495798319,-0.23750952,-5.732118419532118,-5.732118419532118,1.0
24000,1.4188709,23.625,-0.95640874,-5.206814998533668,-5.206814998533668,1.0
27000,1.418871,23.516393442622952,-0.9758483,-5.625797309836403,-5.625797309836403,1.0
30000,1.4188712,23.274193548387096,-0.9727472,-5.800674418768575,-5.800674418768575,1.0
33000,1.418871,23.69672131147541,-0.969294,-5.598607389653315,-5.598607389653315,1.0
36000,1.418871,25.345132743362832,-0.97686756,-6.035144717292448,-6.035144717292448,1.0
39000,1.418871,24.14876033057851,-0.95078397,-5.037369991136977,-5.037369991136977,1.0
42000,1.4187047,24.194915254237287,-1.2236011,-5.816724157939523,-5.816724157939523,1.0
45000,1.4182255,24.525862068965516,-1.6949041,-5.719976039523752,-5.719976039523752,1.0
48000,1.4182254,23.504065040650406,-1.6572313,-5.134700164562318,-5.134700164562318,1.0
51000,1.4182256,23.62295081967213,-1.6832442,-5.59813255804484,-5.59813255804484,1.0
54000,1.4182256,23.858333333333334,-1.6906818,-5.232003391037384,-5.232003391037384,1.0
57000,1.4182255,25.008695652173913,-1.6557826,-5.285290240727622,-5.285290240727622,1.0
60000,1.4182255,24.084745762711865,-1.6914922,-5.549911799551058,-5.549911799551058,1.0
